% !Mode:: "TeX:UTF-8"
%此为章节二模板
%\chapter、\section、\subsection、\subsubsection分别对应一二三四级标题
% file: Chapters/Chapter2.tex
\chapter{时间序列预测相关理论}\label{ch:2}
时间序列即指按照时间顺序排列的一组观测值，其往往具有一定的趋势性、周期性、随机性等特点。我们生活的方方面面都包含着时间序列，例如智能手表的心率监测数据、股票的 Tick 数据、外卖 App 的实时订单量、微信运动每日步数、风力发电机的实时发电功率等等都属时间序列，当然本研究涉及的空气质量数据也是一种时间序列数据。时间序列按连续性分类可以分为连续时间序列和离散时间序列，离散时间序列可以理解为在特定时间点或者间隔多少时间观测一次数据，比如每日股票的收盘价、每月GDP数据等等，连续时间序列则是随时间连续记录数据，例如实时气温监测数据、服务器的实时负载信息。时间序列按特征数量分类可分为单变量时间序列、多元时间序列和高维时间序列，单变量时间序列即只有观测一个特征变量，这个时间序列数据只包含了一个特征变量，比如心率监测数据它只包含心率这一个特征变量，它就是一个单变量时间序列，再比如微信运动每日步数数据只包含步数这一个特征变量，那么它也是一个单变量时间序列。多元时间序列也就是在同一时间轴上同时观测两个或多个特征变量，不同特征变量之间往往会相互影响，比如本研究设计的空气质量监测数据，它往往包含有CO、NO、O3、PM10、PM2.5、SO2、温度、湿度等等多种特征变量，它就是一个典型的多元时间序列。还有像工业IoT中多个传感器设备检测不同的变量，电网多个传感器监测负荷、电价等不同电气量，交通监测路段流量、速度、占用率等都是属于多元时间序列。

\section{时间序列预测方法概述}
对于时间序列的预测有单步预测、多步预测，还有确定性预测以及概率性预测。单步预测一次预测只输出未来的一个时间点的预测值，例如给定真实历史数据 $x_1,x_2,\dots,x_t$，预测 $t+1$ 时刻的值 $\hat{y}_{t+1}$。而多步预测则是模型一次性预测多个未来时间点的值，同样给定真实历史数据 $x_1,x_2,\dots,x_t$，模型一次性预测未来 h 个时间点的值 \(\hat{y}_{t+1},\dots,\hat{y}_{t+h}\)，其中 $h \geq 2$ 为预测步长。对于单步预测模型，其想要实现预测多个未来时间值，可以通过递归的方式实现，就是说其还是一次预测未来一个时间步的值，但是通过将这个预测的时间值作为历史数据再次进行预测下一个时间步的值，直到运行 h 次得到 h 个未来时间的值。但是这样做由于使用了预测值进行预测，而每次预测都会有误差的存在，因此，随着预测时间步数的增长，势必会由于误差的累计导致多步预测的效果越来越差，因此这种通过单步预测模型递归实现多步预测的方式不是一种准确高效的方式，如果需要进行更长期的预测，构建多步预测模型是更好的选择。单步预测和多步预测详细图如\cref{fig:single_multi_step_forecast}所示。

\begin{figure}[htb]
    \centering
    \includegraphics[width=0.8 \textwidth]{single_multi_step_forecast.drawio.png}
    \caption[单步预测与多步预测示意图]{单步预测与多步预测示意图} % 中括号中内容为插图索引中显示内容，可在题注内容过长时使用
    \label{fig:single_multi_step_forecast} % 用于在正文中引用该图片，如图~\ref{fig:single_multi_step_forecast}
\end{figure}


对于本研究涉及的空气质量数据预测，其具有自己的特殊性。空气质量数据一般是多元的，其一般涉及多种不同的变量，例如 PM2.5、PM10、O3、碳化物、氮化物、硫化物等等。同时其中一个空气质量监测站的数据往往也同时跟其他一些空气质量监测站有着强关联性，比如目标站点附近的站点的空气质量数据往往更目标站点有着很强的相关性，然后同时，在目标站点上风向的监测站点数据往往对于目标站点也有很强的影响，可能表现为目标站点一个特征变量的时间序列数据是上风向一些站点的延时序列。因此对于空气质量数据，只考虑一个目标站点的数据往往是不够的，综合考虑多个站点的数据通常可以获得更多有用的信息以提高预测的性能。空气质量预测同时也受其他因素的强影响，具体的气象因素就会对空气质量产生很大的影响，比如天气情况、风速风向等，下雨天由于雨水的对颗粒物的附着以及有一些会溶解到水中，因此很多污染物便随着雨水一起沉降到了地面，空气质量也会有所提升，在雨后人们总能够感觉空气是清新的。如果一个地区位于空气污染排放地区的下风向，那么这个地方的空气质量通常会跟上风向的排放息息相关，同时风速也会影响空气质量，风力越大，污染物的扩散更加迅速，范围更大，从而起到稀释作用，空气质量会更加好一些。因此不同的气象因素与污染物浓度之间有着复杂的非线性关系，另一方面，不同污染物之间也可能产生不同的化学反应进一步加强了非线性性，增加了空气质量预测任务的挑战。

综上所述，空气质量预测任务不仅涉及多元变量之间的耦合关系，还受到气象条件和污染物化学反应的影响，表现出显著的非线性特征。这种复杂性决定了单一的线性模型难以满足预测需求。为此，研究者们在不同阶段提出了多种预测方法：早期主要依赖传统统计方法，如 ARIMA、SARIMA 等，它们在处理平稳单变量序列时具有一定优势；随后，机器学习方法逐渐兴起，能够突破线性假设，更好地刻画非线性关系；近年来，随着数据规模和计算能力的提升，深度学习方法成为主流，凭借自动特征提取和强大的时序建模能力，在空气质量预测中展现出独特优势。下面将依次介绍这些方法。

\subsection{传统统计方法}

从时间序列预测方法的发展历程来看，最早期的时间序列预测方法主要是基于传统的统计学方法，这些方法通常假设时间序列数据是平稳的，并且主要关注数据的线性特征。常见的传统统计方法包括指数平滑、自回归模型（AR）、移动平均模型（MA）、自回归移动平均模型（ARMA）以及自回归积分滑动平均模型（ARIMA）等。这些方法通过对历史数据进行建模，捕捉时间序列中的趋势和季节性变化，实现对未来数据的预测。

（1）指数平滑法(Exponential Smoothing)

在日常生活中，离我们越近的时间点，蕴含的信息通常越有价值。指数平滑（Exponential Smoothing）方法正是基于这一理念，通过对历史数据赋予不同的权重来进行预测。具体来说，指数平滑方法会对较近的观测值赋予更高的权重，而对较远的观测值赋予较低的权重，从而使得模型更加关注近期的数据变化。而且，这个权重是随着时间推移呈指数级衰减的也就是离现在越远，影响力消失得越快。其最基础的一次指数平滑公式可以通俗地表示为 \(S_t = \alpha X_t + (1 - \alpha) S_{t-1}\)，其中，\(S_t\) 是 \(t\) 时刻的平滑值，在无趋势假设下，它直接作为下一 \(t+1\) 时刻的预测值；\(X_t\) 是在 \(t\) 时刻的实际观测值，\(\alpha\) 则是指数平滑的核心：平滑系数，取值范围在 0 到 1 之间。平滑系数 \(\alpha\) 就像一个调节阀，当 \(\alpha\) 越接近 1 时，模型更加依赖近期的观测值，而当 \(\alpha\) 较小时，模型则更倾向于保持长期趋势的稳定，对短期波动的反应比较缓慢。指数平滑方法适用于没有明显趋势和季节性变化的时间序列数据，对于短期预测效果较好，但对于具有复杂模式的时间序列数据，预测效果有限。

（2）自回归模型 (AR)

自回归模型（Autoregressive Model, AR）是常见的时间序列预测模型，它通过线性组合过去的观测值来预测当前值。其数学表达式为 \(X_t = c + \sum_{i=1}^{p} \varphi_i X_{t-i} + \varepsilon_t\)
其中，\(X_t\) 表示时间序列在时间点 \(t\) 的值，\(c\) 是常数项，\(\varphi_i\) 是自回归系数，他们表示过去观测值对当前值的影响权重，\(\varepsilon_t\) 是白噪声误差项，\(p\) 是模型的阶数。
当 \(p=1\) 时，AR 模型简化为一阶自回归模型（AR(1)），其表达式为 \(X_t = c + \varphi_1 X_{t-1} + \varepsilon_t\)，可以看作当前值 \(X_t\) 主要受前一个时间点 \(X_{t-1}\) 的观测值影响，再加上一个常数和一些随机白噪声。当 \(\varphi_1 > 0\) 时，模型表现出正向依赖性，即上一个时刻是高值，则当前值也倾向于高值；当 \(\varphi_1 < 0\) 时，模型表现出负向依赖性，即上一个时刻是高值，则当前值倾向于低值。 \(p=2\) 时则考虑前两个时间点 \(X_{t-1}\) 和 \(X_{t-2}\) 的影响，依此类推。

（3）移动平均模型 (MA)

与自回归模型（Autoregressive Model, AR）不同的是移动平均模型（Moving Average Model, MA）不通过使用预测变量的过去观测值来进行回归预测，而是通过线性组合过去的误差项来预测当前值。其数学表达式为 \(X_t = \mu + \sum_{i=1}^{q} \theta_i \varepsilon_{t-i} + \varepsilon_t\)，
其中，\(\mu\) 是时间序列数据的均值，\(\theta_i\) 是移动平均系数，表示过去误差项对当前值的影响权重，\(\varepsilon_t\) 是白噪声误差项，\(q\) 是模型的阶数。对于这个模型，我们一般称之为 MA(q) 模型，也就是移动平均模型的 q 阶模型。
当 \(q=1\) 时，MA 模型简化为一阶移动平均模型（MA(1)），其表达式为 \(X_t = \mu + \theta_1 \varepsilon_{t-1} + \varepsilon_t\)，可以看作当前值 \(X_t\) 主要受前一个时间点的误差项 \(\varepsilon_{t-1}\) 影响，再加上一个均值和当前的误差项。当 \(\theta_1 > 0\) 时，模型表现出正向依赖性，即前一个误差项为正，则当前值倾向于高值；当 \(\theta_1 < 0\) 时，模型表现出负向依赖性，即前一个误差项为正，则当前值倾向于低值。 \(q=2\) 时则考虑前两个误差项 \(\varepsilon_{t-1}\) 和 \(\varepsilon_{t-2}\) 的影响，依此类推。

（4）ARMA 与 ARIMA 模型

自回归移动平均模型（Autoregressive Moving Average Model, ARMA）结合了自回归模型（AR）和移动平均模型（MA）两者的优点，它主要是通过同时考虑过去的观测值和误差项来进行预测。其数学表达式为 \(X_t = c + \sum_{i=1}^{p} \varphi_i X_{t-i} + \sum_{j=1}^{q} \theta_j \varepsilon_{t-j} + \varepsilon_t\)，
其中，\(c\) 是常数项，\(\varphi_i\) 是自回归系数，表示过去观测值对当前值的影响权重，\(\theta_j\) 是移动平均系数，表示过去误差项对当前值的影响权重，\(\varepsilon_t\) 是白噪声误差项，\(p\) 和 \(q\) 分别是自回归和移动平均部分的阶数。ARMA 模型适用于平稳时间序列数据，通过调整 \(p\) 和 \(q\) 的值，可以灵活地捕捉时间序列中的各种模式，但是现实中的时间序列数据往往具有一定的趋势性，也就是说是非平稳的。
对于非平稳时间序列数据，自回归积分滑动平均模型（Autoregressive Integrated Moving Average Model, ARIMA）则是一种更为通用的模型。ARIMA 模型通过对时间序列数据进行差分处理，使其变得平稳，然后再应用 ARMA 模型进行预测。其数学表达式为 \(\Delta^d X_t = c + \sum_{i=1}^{p} \varphi_i \Delta^d X_{t-i} + \sum_{j=1}^{q} \theta_j \varepsilon_{t-j} + \varepsilon_t\)，
其中，\(\Delta^d\) 表示对时间序列数据进行 \(d\) 次差分处理，消除其非平稳性。通过引入差分阶数 \(d\)，ARIMA 极大地扩展了传统统计方法的适用范围，成为了时间序列分析中经典的“万能模型”。

然而，现实世界的时间序列数据（空气质量数据、传感器网络数据等）通常不是简单的线性的，而是多变量多来源的，传统统计方法在处理非线性关系和多变量时间序列时存在一定的局限性，难以充分挖掘数据中的复杂模式。

\subsection{机器学习方法}

% 完全AI生成，还需要人工润色

鉴于传统统计模型在处理多源异构数据和非线性关系时的不足，基于数据驱动的机器学习方法为解决复杂时间序列预测问题提供了新的思路。传统方法往往需要严格的模型假设（如平稳性检验、白噪声检验），且难以容纳高维度的外部特征变量。而在大数据背景下，数据量的激增和维度的扩展使得传统方法的参数估计变得困难。

相比之下，机器学习方法通过从历史数据中通过训练习得规律，能够更加灵活地处理高维特征输入。在时间序列预测任务中，机器学习方法通常将时间序列问题转化为监督学习问题，通过构造滞后特征（Lag Features）和引入外部协变量，利用强大的非线性拟合能力来逼近时间序列的真实演化规律。

目前，应用于时间序列预测的经典机器学习算法包括支持向量机（Support Vector Machine, SVM）、随机森林（Random Forest, RF）、XGBoost 等。

（1）支持向量回归 (Support Vector Regression, SVR)

支持向量机最初是为了解决分类问题而提出的，但引入 $\varepsilon$-不敏感损失函数后，便可应用于回归问题，即支持向量回归（SVR）。SVR 的核心思想是将输入数据通过核函数映射到高维特征空间，在高维空间中寻找一个线性回归超平面，使得所有样本点到该超平面的距离最小化。与传统回归方法致力于最小化经验误差（如均方误差）不同，SVR 基于结构风险最小化原则（Structural Risk Minimization, SRM），在最小化训练误差的同时约束模型的复杂度。这一特性使得 SVR 在处理小样本、高维及非线性时间序列数据时具有较好的泛化能力，能够有效避免过拟合问题。

（2）随机森林 (Random Forest, RF)

随机森林是一种基于集成学习（Ensemble Learning）的算法，它属于 Bagging（Bootstrap Aggregating）策略的代表。该方法通过构建多棵决策树（Decision Tree）来进行预测，最终的预测结果由所有决策树预测值的平均值决定。在构建每一棵树时，随机森林引入了样本随机采样和特征随机选择的双重随机性。这种机制不仅增加了模型的多样性，还增强了模型对噪声的鲁棒性。对于多变量时间序列预测任务，随机森林能够有效处理高维输入，并且能够评估各个特征（如不同气象因子）对预测目标的重要性，具有较强的抗干扰能力。

（3）XGBoost (eXtreme Gradient Boosting)

XGBoost 是对梯度提升决策树（GBDT）算法的一种高效实现和改进。它采用 Boosting 策略，以加法模型的方式迭代地训练一组弱学习器（通常是分类回归树 CART），每一步都试图拟合上一轮预测结果的残差。与传统的 GBDT 相比，XGBoost 在目标函数中引入了正则化项来控制模型复杂度，并利用泰勒展开对损失函数进行二阶近似，从而加快了收敛速度并提升了预测精度。此外，XGBoost 支持并行计算和缺失值自动处理，这使其在处理大规模、非结构化或存在缺失值的现实时间序列数据（如传感器故障导致的空气质量数据缺失）时表现出卓越的性能。

\section{深度学习基础理论} % 简要回顾深度学习核心组件，为Transformer铺垫。避免太基础（如CNN细节），重点与时间序列相关的部分。

\subsection{神经网络基础}

\subsection{序列模型}

\subsection{注意力机制}

\section{Transformer 模型原理}


\section{本章小节}
本章介绍了 xxx 