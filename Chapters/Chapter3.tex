% !Mode:: "TeX:UTF-8"
%此为章节三模板
%\chapter、\section、\subsection、\subsubsection分别对应一二三四级标题
% file: Chapters/Chapter3.tex

\chapter{基于 ST-PatchTST 的空气质量预测模型构建}\label{ch:3}

**写作目标**：这是论文的灵魂。要让别人觉得你的模型设计得有理有据，数学推导严谨。

\section{问题定义与模型总体框架}

\subsection{多元时间序列预测问题数学描述}

定义输入张量 $X \in \mathbb{R}^{T \times N \times C}$（时间步×站点数×特征数），输出 Y。

\subsection{ST-PatchTST 模型整体架构图}

**[核心图表]** 画一张大图，展示数据流向：输入 -> 空间聚合 -> Patching -> Transformer Encoder -> 输出。

\section{多站点空间特征聚合策略 (Spatial Feature Aggregation)}

\subsection{空间关联结构的定义与筛选策略}

**[写公式]** 给出皮尔逊相关系数（PCC）公式；说明筛选相关站点数据的方法；定义邻接矩阵 A 的生成规则（PCC>threshold 则连边）。说明这是一种“静态图”构建方式。

\subsection{空间特征聚合模块设计 (Spatial Aggregation Module)}

解释数据是如何通过这个邻接矩阵进行交互的。例如：使用了图卷积公式 \(H(l+1)=σ(D~−21A~D~−21H(l)W(l))\) 或者简单的加权求和。


\section{基于 PatchTST 的时序特征提取}

\subsection{Patching 分块机制}

画图解释怎么把长序列切成小块（Patch），说明这样做的两个好处：降低计算量、提取局部语义。


\subsection{通道独立 (Channel Independence) 的应用}

解释为什么把每个站点/变量看作独立的序列输入到 Transformer 中（为了保持鲁棒性，防止噪声干扰）。

\subsection{Transformer 编码器结构}

详细描述 Encoder Layer 内部：多头注意力 + 前馈神经网络 + 残差连接 + BatchNorm 。

\section{预测输出模块}

Flatten 层 -> Linear 线性层映射到未来时间步。

\section{损失函数与优化策略}

Loss: MSE 或 MAE 公式。

Optimizer: AdamW 优化器。

Strategy: Early Stopping（早停机制）。

\subsection{本章小结}